Tags: #Polling #DMA #Driver #Interrupt #Multicore #Multiprocessing #Cache #Periferiche

# Periferiche
Per interrompere un software si deve usare un interrupt request che è un collegamento fisico sulla cpu
NMI: non maskerable interrupt
#### [Polling](https://it.wikipedia.org/wiki/Polling_(informatica))
Cpu interroga a ciclo se le periferiche hanno nuovi dati. Non efficiente. 
#### [DMA](https://it.wikipedia.org/wiki/Direct_Memory_Access)
Direct Memory access. Meglio del polling. Sfrutta l'interrupt: quando l'intterrupt è acceso la cpu controlla quale periferica abbia "suonato" dal bus dei dati dove la periferica scrive il suo numero e legge i dati nuovi da quella periferica. Cpu risponde con un INTA
	Cercare cache DMA
	Pre fetch: prelievo anticipato di dati che servono al processore messi nella cache
	DMA controller gestisce il DMA
#### INTA
INTA o Interrupt acknowledge è un segnale che manda la cpu per dire alla periferica che ha letto l'interrupt
#### Driver
Ogni periferica ha bisogno di driver possono essere scritti dal produttore della periferica o driver generici universali già presenti nel SO

#### Gestione delle periferiche
MCH
Memory controller Hub controlla 
ICH
PCH
Unione MCH e ICH ma la ram la gestisce la cpu
# Multicore
Multipli "processori" in una cpu
Ogni core della cpu ha una cache L1 e condividono una cache L2 più grande
#### NUMA
Non Uniform Memory Access ogni CPU(fisica) ha un proprio banco di memoria che possono essere anche letti tra loro
### Cache
La cache pre immagazzina i dati della ram che serviranno poco dopo alla cpu per velocizzare la lettura dalla ram. La cache per avere dati da servire alla cpu fa il pre fetch mentre la cpu non sta leggendo così da evitare cache miss della cpu appena rileggera la memeria. Quando ho piccole funzioni o loop che utilizzano sempre le stesse variabili vengono immagazzinate nella cache per evitare di andare in ram e velocizzare l'esecuzione del programma
	L1, L2, L3 fanno tutte le stese cose sempre più grandi ma meno veloci per evitare di leggere la ram
#### Coerenza cache
Con il multi core le cache devono essere coerenti(avere variabili uguail), quindi si usa 
un bus che collega le cache L1 così che quando una cache L1 modifica una variabile aggiorna anche le altre cache L1